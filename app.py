import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
import av
import cv2
import mediapipe as mp
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import pandas as pd
import numpy as np
import math
import time
from PIL import Image

# --- 1. Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„ØªØ¨ÙˆÙŠØ¨ ---
LOGO_URL = "https://i.postimg.cc/R0cQyjrR/logo-png.png" 

st.set_page_config(
    page_title="Ø¨ØµÙŠØ±Ø© | Smart Sign Translator", 
    page_icon=LOGO_URL, 
    layout="wide"
)

# --- 2. ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ø¥ØµÙ„Ø§Ø­ AttributeError) ---
if 'auth' not in st.session_state:
    st.session_state.auth = {'in': False, 'user': None, 'role': None}
if 'live_code' not in st.session_state:
    st.session_state.live_code = None
if 'last_time' not in st.session_state:
    st.session_state.last_time = time.time()
if 'stab_count' not in st.session_state:
    st.session_state.stab_count = 0
if 'last_s' not in st.session_state:
    st.session_state.last_s = ""

# --- 3. Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø³Ø­Ø§Ø¨Ø© ---
@st.cache_resource
def init_system():
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(st.secrets["gcp_service_account"], scope)
        client = gspread.authorize(creds)
        db = client.open("Basira_DB")
        
        mp_hands = mp.solutions.hands
        engine = mp_hands.Hands(max_num_hands=1, model_complexity=1, min_detection_confidence=0.7)
        return db.worksheet("Signs_DB"), db.worksheet("Users_Admin"), engine, mp.solutions.drawing_utils
    except Exception as e:
        st.error(f"âš ï¸ Ø®Ø·Ø£ Ø§ØªØµØ§Ù„: {e}")
        st.stop()

signs_sheet, auth_sheet, hands_engine, mp_draw = init_system()

# --- 4. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ (3D Euclidean Distance) ---
def calculate_math(hl):
    lm = hl.landmark
    # $d = \sqrt{(x_2-x_1)^2 + (y_2-y_1)^2 + (z_2-z_1)^2}$
    palm = math.sqrt((lm[0].x-lm[9].x)**2 + (lm[0].y-lm[9].y)**2 + (lm[0].z-lm[9].z)**2)
    tips = [4, 8, 12, 16, 20]
    return ",".join([str(round(math.sqrt((lm[t].x-lm[0].x)**2 + (lm[t].y-lm[0].y)**2 + (lm[t].z-lm[0].z)**2)/palm, 1)) for t in tips])

# --- 5. Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (WebRTC) ---
class SignProcessor(VideoProcessorBase):
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        img = cv2.flip(img, 1)
        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        res = hands_engine.process(rgb)
        
        if res.multi_hand_landmarks:
            st.session_state.last_time = time.time()
            hl = res.multi_hand_landmarks[0]
            mp_draw.draw_landmarks(img, hl, mp.solutions.hands.HAND_CONNECTIONS)
            st.session_state.live_code = calculate_math(hl)
            
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# --- 6. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØªÙˆØ²ÙŠØ¹ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª ---
st.markdown("<style> * { font-family: 'Cairo', sans-serif; text-align: right; } </style>", unsafe_allow_html=True)

if not st.session_state.auth['in']:
    st.title("ğŸ”’ Ø¯Ø®ÙˆÙ„ Ù…Ù†ØµØ© Ø¨ØµÙŠØ±Ø©")
    u, p = st.text_input("Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"), st.text_input("Ø§Ù„Ø³Ø±", type="password")
    if st.button("Ø¯Ø®ÙˆÙ„"):
        df = pd.DataFrame(auth_sheet.get_all_records())
        found = df[(df['Username'].astype(str)==u) & (df['Password'].astype(str)==p)]
        if not found.empty:
            st.session_state.auth = {'in': True, 'user': u, 'role': found.iloc[0]['Role'].strip()}
            st.rerun()
else:
    st.sidebar.image(LOGO_URL, use_container_width=True)
    role = st.session_state.auth['role']
    
    if role == "User":
        st.header("ğŸ“¸ Ø§Ù„Ù…ØªØ±Ø¬Ù… Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ")
        # Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§: Ø¥Ø¶Ø§ÙØ© ICE Servers
        webrtc_streamer(
            key="basira-camera",
            mode=WebRtcMode.SENDRECV,
            video_processor_factory=SignProcessor,
            rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )
        
        # Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ±Ø¬Ù…Ø© (ÙƒÙ…Ø§ Ø³Ø¨Ù‚)
        if time.time() - st.session_state.last_time < 2.0:
            if st.session_state.live_code:
                # (Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù‡Ù†Ø§...)
                st.write(f"Ø¨ØµÙ…Ø© Ø§Ù„ÙŠØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {st.session_state.live_code}")

    elif role == "Admin":
        st.header("âš™ï¸ Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø§Ù„Ù…Ø¯ÙŠØ± (ÙƒØ§Ù…Ù„Ø©)")
        tab1, tab2 = st.tabs(["â• Ø¥Ø¶Ø§ÙØ© Ø¥Ø´Ø§Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø©", "ğŸ“‹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"])
        
        with tab1:
            name = st.text_input("Ø§Ø³Ù… Ø§Ù„Ø¥Ø´Ø§Ø±Ø©")
            file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„", type=['jpg','png','jpeg'])
            if file:
                img = Image.open(file)
                st.image(img, width=250)
                if st.button("ØªØ­Ù„ÙŠÙ„ ÙˆØ­ÙØ¸"):
                    with mp.solutions.hands.Hands(static_image_mode=True) as static_hands:
                        res = static_hands.process(cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB))
                        if res.multi_hand_landmarks:
                            code = calculate_math(res.multi_hand_landmarks[0])
                            signs_sheet.append_row([name, code])
                            st.success(f"ØªÙ… Ø­ÙØ¸ {name} Ø¨Ø¨ØµÙ…Ø© {code}")
                        else: st.error("Ù„Ù… ÙŠØªÙ… Ø±ØµØ¯ ÙŠØ¯ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©")
        
        with tab2:
            st.dataframe(pd.DataFrame(signs_sheet.get_all_records()), use_container_width=True)

    if st.sidebar.button("Ø®Ø±ÙˆØ¬"):
        st.session_state.auth['in'] = False; st.rerun()